
import os
import json
import re
import requests
from dotenv import load_dotenv
from operator import itemgetter 

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema.output_parser import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage # ğŸ’¡ í•„ìš”í•œ Import ì¶”ê°€
from db.history_module import get_user_history_all
# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from gemini.prompt_module import choose_chat_prompt
# from db.history_module import get_user_history # ì‹¤ì œ DB ëª¨ë“ˆì´ ì—†ìœ¼ë¯€ë¡œ ì„ì‹œ í•¨ìˆ˜ë¡œ ëŒ€ì²´

# ----------------------------------------------------
# ì„ì‹œ DB í•¨ìˆ˜ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” DB ëª¨ë“ˆë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)



def prep_for_scoring(session_id: str, scenario: str, llm) -> str:
    """
    ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•˜ê³ ,
    LLMì—ê²Œ ì „ì²´ scoring JSON ìƒì„±ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜ (LangChain ì œê±° ë²„ì „)
    """
    try:
        # 1ï¸âƒ£ DBì—ì„œ ê³¼ê±° íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
        history_data = get_user_history_all(session_id)

        # 2ï¸âƒ£ historyë¥¼ ë³´ê¸° ì¢‹ê²Œ ë¬¸ìì—´ í˜•íƒœë¡œ ë³€í™˜
        # ì˜ˆ: user: ì¹˜í‚¨ ì‹œí‚¬ê²Œìš”. / gemini: ì–´ë–¤ ë©”ë‰´ë¡œ ë„ì™€ë“œë¦´ê¹Œìš”?
        history_text = "\n".join(
            [f"{turn['role']}: {turn['content']}" for turn in history_data]
        )

        # 3ï¸âƒ£ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
        # choose_chat_prompt() ë‚´ë¶€ì—ì„œ get_prompt() í˜¸ì¶œë¨
        system_message = choose_chat_prompt(scenario, session_id)

        # 4ï¸âƒ£ ë¬¸ìì—´ í¬ë§· ì‚½ì… (.format ì´ìš©)
        # prep_order í”„ë¡¬í”„íŠ¸ ë‚´ì— {history}, {session_id} ìë¦¬ê°€ ìˆì–´ì•¼ í•¨
        prompt = system_message.format(
            history=history_text,
            session_id=session_id
        )

        # 5ï¸âƒ£ ëª¨ë¸ í˜¸ì¶œ (LangChain chain ì œê±°, ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì…ë ¥)
        response_subject = llm.invoke(prompt)
        if isinstance(response_subject, AIMessage):
            response = response_subject.content
 # 2ï¸âƒ£ ì¶œë ¥ ì •ë¦¬: dictì´ë©´ content ê°€ì ¸ì˜¤ê¸°, ì•„ë‹ˆë©´ strë¡œ ë³€í™˜
        # print("response",response)
        try:
            final_json_data = json.loads(response)
            # ğŸŒŸ ì„±ê³µ! final_json_dataëŠ” ì´ì œ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
            # ì´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì›í•˜ëŠ” ëŒ€ë¡œ í™œìš©í•˜ê±°ë‚˜, ë¬¸ìì—´ë¡œ ë‹¤ì‹œ ë°˜í™˜í•˜ë©´ ë©ë‹ˆë‹¤.
            return final_json_data 
            
        except json.JSONDecodeError as e:
            # í˜¹ì‹œ ëª¨ë¥¼ ì˜¤ë¥˜ ëŒ€ë¹„
            return f"[JSON íŒŒì‹± ì˜¤ë¥˜] {e}"
    except Exception as e:
        return f"[Gemini ì˜¤ë¥˜] {str(e)}"

def preprocess_session(session_id:str):
    # 1ï¸âƒ£ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    # 2ï¸âƒ£ Gemini ëª¨ë¸ ì´ˆê¸°í™” (LangChainìš©)
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: GEMINI_API_KEY=YOUR_API_KEY
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.7,
        google_api_key=os.getenv("GEMINI_API_KEY")
    )
    prep_result=prep_for_scoring(session_id,"prep_order",llm)


    # 3ï¸âƒ£ NestJS APIì— ì €ì¥
    url = "http://localhost:3000/preprocess/save"
    headers = {"Content-Type": "application/json"}
    res = requests.post(url, json=prep_result)
    if res.status_code != 201:
        print(f"[Warning] NestJS ì €ì¥ ì‹¤íŒ¨: {res.status_code}, {res.text}")
    else:
        print("[Info] MongoDB preprocess ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ")

    return "ì¢‹ì€ ê²°ê³¼"




