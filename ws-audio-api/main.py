from fastapi import FastAPI, WebSocket
from stt.stt_module import transcribe_audio
from gemini.gemini_module import ask_gemini
from tts.tts_module import text_to_speech
from vad.vad_module import is_speech_chunk
from fastapi.middleware.cors import CORSMiddleware

from fastapi.responses import FileResponse
import os
import uuid

app = FastAPI()


app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œ ì¤‘ì—ëŠ” * ê°€ëŠ¥ / ë°°í¬ ì‹œ íŠ¹ì • ë„ë©”ì¸ìœ¼ë¡œ ì œí•œ
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
@app.websocket("/ws/audio")
async def websocket_audio(websocket: WebSocket):
    await websocket.accept()
    audio_buffer = b""
    silence_counter = 0
    threshold = 20  # ëª‡ ë²ˆ ì—°ì†ìœ¼ë¡œ ì¹¨ë¬µì´ë©´ 'ì¢…ë‹¨ì 'ìœ¼ë¡œ ê°„ì£¼í• ì§€

    try:
        while True:
            data = await websocket.receive_bytes()
            audio_buffer += data

            if is_speech_chunk(data):
                silence_counter = 0  # ë§ ì¤‘ì´ë©´ ë¦¬ì…‹
            else:
                silence_counter += 1

            if silence_counter > threshold:
                print("ğŸ“¢ ë§ ëë‚œ ê²ƒ ê°™ì•„, STT ì‹œì‘!")

                transcript = transcribe_audio(audio_buffer)
                response_text = ask_gemini(transcript)
                tts_path = text_to_speech(response_text)

                await websocket.send_json({
                    "transcript": transcript,
                    "response": response_text,
                    "audio_id": os.path.basename(tts_path)
                })

                # ì´ˆê¸°í™”
                audio_buffer = b""
                silence_counter = 0

    except Exception as e:
        print(f"[ì—ëŸ¬] {e}")
        await websocket.close()
