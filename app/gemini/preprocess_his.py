
import os
import json
import re
import requests
from dotenv import load_dotenv
from operator import itemgetter 
from typing import Dict, Any, List
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.memory import ConversationBufferMemory
from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.schema.output_parser import StrOutputParser
from langchain_core.messages import HumanMessage, AIMessage # ğŸ’¡ í•„ìš”í•œ Import ì¶”ê°€
from db.history_module import get_user_history_all
# ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸
from gemini.prompt_module import choose_chat_prompt
# from db.history_module import get_user_history # ì‹¤ì œ DB ëª¨ë“ˆì´ ì—†ìœ¼ë¯€ë¡œ ì„ì‹œ í•¨ìˆ˜ë¡œ ëŒ€ì²´

# ----------------------------------------------------
# ì„ì‹œ DB í•¨ìˆ˜ (ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” DB ëª¨ë“ˆë¡œ ëŒ€ì²´ë˜ì–´ì•¼ í•©ë‹ˆë‹¤)



def prep_for_scoring(session_id: str, scenario: str, llm) -> str:
    """
    ì„¸ì…˜ì˜ ëŒ€í™” ê¸°ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•˜ê³ ,
    LLMì—ê²Œ ì „ì²´ scoring JSON ìƒì„±ì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜ (LangChain ì œê±° ë²„ì „)
    """
    try:
        #1) DBì—ì„œ ê³¼ê±° íˆìŠ¤í† ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
        history_data = get_user_history_all(session_id)

        #2) historyë¥¼ ë³´ê¸° ì¢‹ê²Œ ë¬¸ìì—´ í˜•íƒœë¡œ ë³€í™˜
        # ì˜ˆ: user: ì¹˜í‚¨ ì‹œí‚¬ê²Œìš”. / gemini: ì–´ë–¤ ë©”ë‰´ë¡œ ë„ì™€ë“œë¦´ê¹Œìš”?
        history_text = "\n".join(
            [f"{turn['role']}: {turn['content']}" for turn in history_data]
        )

        #3) ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶ˆëŸ¬ì˜¤ê¸°
        # choose_chat_prompt() ë‚´ë¶€ì—ì„œ get_prompt() í˜¸ì¶œë¨
        system_message = choose_chat_prompt(scenario, session_id)

        #4) ë¬¸ìì—´ í¬ë§· ì‚½ì… (.format ì´ìš©)
        # prep_order í”„ë¡¬í”„íŠ¸ ë‚´ì— {history}, {session_id} ìë¦¬ê°€ ìˆì–´ì•¼ í•¨
        prompt = system_message.format(
            history=history_text,
            session_id=session_id
        )

        # ëª¨ë¸ í˜¸ì¶œ (LangChain chain ì œê±°, ë‹¨ìˆœ í…ìŠ¤íŠ¸ ì…ë ¥)
        response_subject = llm.invoke(prompt)
        if isinstance(response_subject, AIMessage):
            response = response_subject.content

        # ì¶œë ¥ ì •ë¦¬: dictì´ë©´ content ê°€ì ¸ì˜¤ê¸°, ì•„ë‹ˆë©´ strë¡œ ë³€í™˜
        # print("response",response)
        try:
            final_json_data = json.loads(response)
            # ğŸŒŸ ì„±ê³µ! final_json_dataëŠ” ì´ì œ íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.
            # ì´ ë”•ì…”ë„ˆë¦¬ë¥¼ ì›í•˜ëŠ” ëŒ€ë¡œ í™œìš©í•˜ê±°ë‚˜, ë¬¸ìì—´ë¡œ ë‹¤ì‹œ ë°˜í™˜í•˜ë©´ ë©ë‹ˆë‹¤.

            #2ì°¨ ìˆ˜ì •ì„ ìœ„í•œ í¬ë§· ì •ë¦¬
            real_final_json_data=convert_to_final_format(final_json_data)
            return real_final_json_data 
            
        except json.JSONDecodeError as e:
            # í˜¹ì‹œ ëª¨ë¥¼ ì˜¤ë¥˜ ëŒ€ë¹„
            return f"[JSON íŒŒì‹± ì˜¤ë¥˜] {e}"
    except Exception as e:
        return f"[Gemini ì˜¤ë¥˜] {str(e)}"


def convert_to_final_format(old_data: Dict[str, Any]) -> Dict[str, Any]:
    """
    ê¸°ì¡´ Mongo-style JSON ë°ì´í„°ë¥¼ ìµœì¢… í•™ìŠµ í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    session_id = old_data.get("session_id", old_data.get("_id", "UNKNOWN_ID"))
    history = old_data.get("history", [])

    #1. historyë¥¼ linearized í…ìŠ¤íŠ¸ë¡œ ë³‘í•©
    sep_token = "[SEP]"
    linearized_text = f" {sep_token} ".join([
        f"{h['role'].upper()}: {h['content']}" for h in history
    ])

    #2. ì¼ì • ê¸¸ì´ ê¸°ì¤€ìœ¼ë¡œ window ë¶„í•  (ì˜ˆ: ëŒ€í™” turn 5ê°œì”©)
    window_size = 5
    windows = []
    for i in range(0, len(history), window_size):
        chunk = history[i:i + window_size]
        chunk_text = f" {sep_token} ".join([f"{h['role'].upper()}: {h['content']}" for h in chunk])
        windows.append({"text": chunk_text})

    #3. history ì¬êµ¬ì„± (messageId, seq ë“± í¬í•¨)
    new_history = []
    for idx, h in enumerate(history, start=1):
        new_history.append({
            "messageId": f"{session_id}-{idx}",
            "seq": idx,
            "role": h["role"],
            "content": h["content"],
            "timestamp": {"$date": None},
            "_id": {"$oid": None}
        })

    #4. ìµœì¢… í¬ë§· êµ¬ì„±
    final_data = {
        "_id": session_id,
        "preprocessId": session_id,
        "view": {
            "max_len_tokens": 256,
            "truncate": {
                "policy": "head_tail",
                "head_turns": 2,
                "tail_turns": 8
            },
            "linearize_sep": sep_token
        },
        "windows": windows,
        "linearized": {"text": linearized_text},
        "history": new_history,
    }

    #5. ì¶”ê°€ ë©”íƒ€ ì •ë³´ ë³µì‚¬
    for key in ["goalSpec", "labels", "meta", "tags"]:
        if key in old_data:
            final_data[key] = old_data[key]

    #6. messageCount ìë™ ê³„ì‚°
    final_data["messageCount"] = len(history)

    return final_data

def preprocess_session(session_id:str):
    #1 í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()

    #2 Gemini ëª¨ë¸ ì´ˆê¸°í™” (LangChainìš©)
    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì •: GEMINI_API_KEY=YOUR_API_KEY
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash",
        temperature=0.7,
        google_api_key=os.getenv("GEMINI_API_KEY")
    )
    prep_result=prep_for_scoring(session_id,"prep_order",llm)


    #3 NestJS APIì— ì €ì¥
    url = "http://localhost:3000/preprocess/save"
    headers = {"Content-Type": "application/json"}
    res = requests.post(url, json=prep_result)
    if res.status_code != 201:
        print(f"[Warning] NestJS ì €ì¥ ì‹¤íŒ¨: {res.status_code}, {res.text}")
    else:
        print("[Info] MongoDB preprocess ì»¬ë ‰ì…˜ì— ì €ì¥ ì™„ë£Œ")

    return prep_result




